"""
python run_image_dir_example.py --use_region --use_depth --use_texture --measure_occlusions -b obj_000014 -m <path/to/obj/dir> -i <path/to/image/dir> -c config/cam_d435_640.yaml -n 10 -s
"""

import cv2
import yaml
import glob
import time
import argparse
import numpy as np
import quaternion
from pathlib import Path

from single_view_tracker import setup_single_object_tracker, ExecuteTrackingStepSingleObject


def parse_script_input():
    parser = argparse.ArgumentParser(
        prog='run_image_dir_example',
        description='Run the m3t tracker image per image reading from rgb/depth folder'
    )

    parser.add_argument('-b', '--body_name',  dest='body_name',  type=str, required=True, help='Name of the object to track. need to match')
    parser.add_argument('-m', '--models_dir', dest='models_dir', type=str, required=True, help='Path to directory where object model file {body_name}.obj is stored')
    parser.add_argument('-c', '--cam_path',   dest='cam_path',   type=str, required=True, help='Path to camera intrinsics file')
    parser.add_argument('-i', '--imgs_dir',   dest='imgs_dir',   type=str, required=True, help='Path to directory where "rbg*" and "depth*" named images are stored')
    parser.add_argument('-n', '--nb_img_load',     dest='nb_img_load',   type=int, default=-1)
    parser.add_argument('-s' '--stop_at_each_img', dest='stop_at_each_img',   action='store_true', default=False)
    parser.add_argument('--scale_geometry', dest='scale_geometry', default=0.001, type=float, required=False, help='Scale factor to convert model geometry to meters.')
    parser.add_argument('--tmp_dir',     dest='tmp_dir',    type=str, default='tmp', help='Directory to store preprocessing files generated by the tracker.')
    parser.add_argument('--use_region',  dest='use_region', action='store_true', default=False)
    parser.add_argument('--use_depth',   dest='use_depth', action='store_true', default=False)
    parser.add_argument('--use_texture', dest='use_texture', action='store_true', default=False)
    parser.add_argument('--use_depth_viewer', dest='use_depth_viewer', action='store_true', default=False)
    parser.add_argument('--measure_occlusions', dest='measure_occlusions', action='store_true', default=False)

    return parser.parse_args()

args = parse_script_input()

# Load camera intrinsics from yaml file
with open(args.cam_path, 'r') as f:
    cam_intrinsics = yaml.load(f.read(), Loader=yaml.UnsafeLoader)

if args.use_depth:
    tracker, optimizer, body, link, color_camera, depth_camera, color_viewer, depth_viewer = setup_single_object_tracker(args, cam_intrinsics)
else:
    tracker, optimizer, body, link, color_camera, color_viewer = setup_single_object_tracker(args, cam_intrinsics)

imgs_dir = Path(args.imgs_dir)
if not imgs_dir.exists():
    print(f'Wrong path to image directory: {imgs_dir}')
# read images from disk
color_names = sorted(glob.glob((imgs_dir / 'color*').as_posix()))
depth_names = sorted(glob.glob((imgs_dir / 'depth*').as_posix()))

# LIMIT nb images
color_names = color_names[:args.nb_img_load]
depth_names = depth_names[:args.nb_img_load]
print(f'Loading {len(color_names)} images...')

# load images from disk
color_read_flags = cv2.IMREAD_COLOR + cv2.IMREAD_ANYDEPTH
img_bgr_lst = [cv2.imread(name, color_read_flags) for name in color_names]  # loads a dtype=uint8 array
depth_read_flags = cv2.IMREAD_GRAYSCALE + cv2.IMREAD_ANYDEPTH
img_depth_lst = [cv2.imread(name, depth_read_flags) for name in depth_names]  # loads a dtype=uint8 array

#----------------
# Initialize object pose
body2world_pose = np.array([ 1, 0,  0, 0,
                             0, 0, -1, 0,
                             0, 1,  0, 0.456,
                             0, 0,  0, 1 ]).reshape((4,4))
dR_l = quaternion.as_rotation_matrix(quaternion.from_rotation_vector([0.2,0,0.0]))
body2world_pose[:3,:3] = body2world_pose[:3,:3] @ dR_l
#----------------

SLEEP = int(1000/30)  # frames at 30 Hz

print('\n------\nPress q to quit during execution')
print('Press any other key to step to next image')


#----------------------
# TODO: tweak tikhonov regularization to observe effect on tracking stability 
scale_t = 1
scale_r = 1
optimizer.tikhonov_parameter_translation *= scale_t
optimizer.tikhonov_parameter_rotation *= scale_r
optimizer.SetUp()
#----------------------

# Simulate one iteration of Tracker::RunTrackerProcess for loop
for i, (img_bgr, img_depth) in enumerate(zip(img_bgr_lst, img_depth_lst)):
    t1 = time.time()
    print('\nIteration: ', i)
    # 1) Update camera image -> replaces a call to the camera UpdateImage method (which does nothing for Dummy(Color|Depth)Camera) 
    color_camera.image = img_bgr
    if args.use_depth:
        depth_camera.image = img_depth
    ok = tracker.UpdateCameras(True)  # poststep verifying the images have been properly setup
    if not ok:
        raise ValueError('Something is wrong with the provided images')

    if i == 0:
        # 2) Use external init to update initial object pose
        body.body2world_pose = body2world_pose  # simulate external initial pose

    # 3) One tracking cycle
    t = time.time()

    #----------------------
	# TODO: uncomment/comment to replace by custom implementation 
    tracker.ExecuteTrackingStep(i)
    # ExecuteTrackingStepSingleObject(tracker, link, body, i, tikhonov_trans, tikhonov_rot)
    print('ExecuteTrackingCycle (ms)', 1000*(time.time() - t))
    print('body.body2world_pose\n',body.body2world_pose)
    #----------------------

    # 4) Render results
    t = time.time()
    color_viewer.UpdateViewer(i)
    if args.use_depth and args.use_depth_viewer:
        depth_viewer.UpdateViewer(i)
    print('Updating viewers took (ms)', 1000*(time.time() - t))
    
    if args.stop_at_each_img:
        k = cv2.waitKey(0)
    else:
        delay = time.time() - t1
        sleep = max(1, SLEEP - int(1000*delay))
        k = cv2.waitKey(sleep)
    if k == ord('q'):
        break
